import os
import io
import argparse
from os.path import exists, join
from abc import ABCMeta
from collections import defaultdict
from typing import Dict, List, Iterator, Iterable, Any, Optional
from ..package import Package
from ..instance import Instance
from ..target import Target
from ..util import Namespace, FatalError, run


class Tool(Package, metaclass=ABCMeta):
    def ident(self):
        return self.name

    def fetch(self, ctx):
        pass

    def build(self, ctx):
        self._run_make(ctx, '-j%d' % ctx.jobs)

    def install(self, ctx):
        self._run_make(ctx, 'install')

    def is_fetched(self, ctx):
        return True

    def is_built(self, ctx):
        return all(exists(join('obj', f)) for f in self.built)

    def is_installed(self, ctx):
        return all(exists(join('install', f)) for f in self.installed)

    def _srcpath(self, ctx, *args):
        return join(ctx.paths.infra, 'tools', self.name, *args)

    def _run_make(self, ctx, *args):
        os.chdir(self._srcpath(ctx))
        run(ctx, [
            'make',
            'OBJDIR=' + self.path(ctx, 'obj'),
            'INSTALLDIR=' + self.path(ctx, 'install'),
            *args
        ])


class Nothp(Tool):
    """
    :identifier: nothp
    """
    name = 'nothp'
    built = ['nothp']
    installed = ['bin/nothp']


class BenchmarkUtils(Tool):
    """
    Utility class for the :ref:`report <usage-report>` command. Should be
    generated by :func:`Target.dependencies` by a target that uses the
    utilities. See :class:`SPEC2006` for an example.

    Defines a static library to be linked into the target binary. The library
    prints some usage data such as memory usage to ``stderr``, prefixed by
    ``[setup-report]``. These numbers can be aggregated at report time.

    The package also defines a number of utility methods for reading and
    writing metadata to/from log files in the ``results/`` directory after a
    parallel benchmark run. Metadata is organised in "results" with each result
    being a dictionary of properties corresponding to a program invocation.

    Note that :func:`parse_logs`, which is used for reporting, requires the
    ``parse_outfile()`` method to be implemented by the target.

    :identifier: benchmark-utils
    :param target: the target that will be run
    """
    name = 'benchmark-utils'
    built = ['libbenchutils.a']
    installed = ['lib/libbenchutils.a']

    #: :class:`str` prefix for metadata lines in output files
    prefix = '[setup-report]'

    LoggedResult = Dict[str, Any]
    ParsedResult = Namespace

    def __init__(self, target: Optional[Target] = None):
        self.target = target

    def add_report_args(self, parser: argparse.ArgumentParser):
        parser.add_argument('rundirs',
                nargs='+', metavar='RUNDIR', default=[],
                help='run directories to parse (results/run.XXX)')

    def configure(self, ctx: Namespace):
        """
        Set build/link flags in **ctx**. Should be called from the
        ``build`` method of a target to link in the static library.

        :param ctx: the configuration context
        """
        ctx.ldflags += ['-L', self.path(ctx, 'install/lib'),
                        '-Wl,--whole-archive', '-l:libbenchutils.a',
                        '-Wl,--no-whole-archive']

    def pkg_config_options(self, ctx):
        yield ('--includes', 'include path for reporting helpers',
               ['-I', self._srcpath(ctx)])
        yield from super().pkg_config_options(ctx)

    def outfile_path(self, ctx: Namespace, instance: Instance,
                     benchmark: str) -> str:
        """
        Returns the path to a log file for tha benchmark of a particular
        instance, after creating the instance directory if it did not exist
        yet.

        :param ctx: the configuration context
        :param instance: instance to which the benchmark belongs
        :param benchmark: benchmark name (log file name)
        :returns: ``results/run.YY-MM-DD.HH-MM-SS/<target>/<instance>/<benchmark>``
        """
        rundir = ctx.starttime.strftime('run.%Y-%m-%d.%H-%M-%S')
        instancedir = os.path.join(ctx.paths.pool_results, rundir,
                                   self.target.name, instance.name)
        os.makedirs(instancedir, exist_ok=True)
        return os.path.join(instancedir, benchmark)

    def parse_logs(self, ctx: Namespace,
                   instances: List[Instance],
                   rundirs: Iterable[str],
                   cache: bool = True
                   ) -> Dict[str, List[ParsedResult]]:
        """
        Parse logs from specified run directories.

        Traverse the directories to find log files, parse each logfile, and
        optionally append the parsed results to the log file. To get results
        for a log file, :func:`Target.parse_outfile` is called on the target.
        This should parse the log file and yield a number of result
        dictionaries of results found in the log file (e.g., an entry for each
        benchmark runtime). The parsed results are grouped per instance and
        returned as an ``{<instance_name>: [<result>, ...]}`` dictionary.

        If ``cache`` is true (which is the default), the results returned by
        each invocation of :func:`Target.parse_outfile` are logged into the log
        file itself, and read from there in the next invocation of the report
        command. This means that expensive log file parsing is only done on the
        first invocation, and also that the log files become portable across
        systems without having to also copy any files referenced by the logs.

        :param ctx: the configuration context
        :param instances: list of instances to filter from, leave empty to get
                          results for all instances in the logs
        :param rundirs: run directories to traverse
        :param cache: whether to append log file results to the log file
                      itself, and to read existing results from log files
                      instead of calling ``Target.parse_outfile``
        """
        abs_rundirs = []
        for d in rundirs:
            if not os.path.exists(d):
                raise FatalError('rundir %s does not exist' % d)
            abs_rundirs.append(os.path.abspath(d))

        instance_names = [instance.name for instance in instances]
        instance_dirs = []
        results = dict((iname, []) for iname in instance_names)

        for rundir in abs_rundirs:
            targetdir = os.path.join(rundir, self.target.name)
            if os.path.exists(targetdir):
                for instance in os.listdir(targetdir):
                    instancedir = os.path.join(targetdir, instance)
                    if os.path.isdir(instancedir):
                        if not instance_names or instance in instance_names:
                            instance_dirs.append((instance, instancedir))
            else:
                ctx.log.warning('rundir %s contains no results for target %s' %
                                (rundir, self.target.name))

        for iname, idir in instance_dirs:
            instance_results = results.setdefault(iname, [])

            for filename in sorted(os.listdir(idir)):
                path = os.path.join(idir, filename)
                cached = []

                if cache:
                    for result in self.parse_results(ctx, path):
                        if result.get('cached', False):
                            cached.append(result)

                if cached:
                    fresults = cached
                    ctx.log.debug('using cached results from ' + path)
                else:
                    fresults = []
                    ctx.log.debug('parsing outfile ' + path)
                    for result in self.target.parse_outfile(ctx, iname, path):
                        result['cached'] = False
                        fresults.append(result)

                    if cache:
                        ctx.log.debug('caching %d results' % len(fresults))
                        with open(path, 'a') as f:
                            for result in fresults:
                                self._log_result({**result, 'cached': True}, f)

                for result in fresults:
                    result['outfile'] = path

                instance_results += fresults

        return results

    @classmethod
    def _log_result(cls, result: LoggedResult, ofile: io.TextIOWrapper):
        """
        :param result:
        :param ofile:
        """
        print(cls.prefix, 'begin', file=ofile)

        for key, value in result.items():
            print(cls.prefix, key + ':', _box_value(value), file=ofile)

        print(cls.prefix, 'end', file=ofile)

    @classmethod
    def parse_results(cls, ctx: Namespace, path: str) -> Iterator[ParsedResult]:
        """
        Parse existing results from a file. Can be used by a
        :func:`Target.parse_outfile` implementation to parse results written by
        the static library in the stderr log of a target.

        :param ctx: the configuration context
        :param path: path to file to parse
        """
        with open(path) as f:
            result = None

            for line in f:
                line = line.rstrip()
                if line.startswith(cls.prefix):
                    statement = line[len(cls.prefix) + 1:]
                    if statement == 'begin':
                        result = Namespace()
                    elif statement == 'end':
                        yield result
                        result = None
                    elif result is None:
                        ctx.log.error('ignoring %s statement outside of begin-end '
                                    'in %s' % (cls.prefix, path))
                    else:
                        name, value = statement.split(': ', 1)

                        if name in result:
                            ctx.log.warning('duplicate metadata entry for "%s" in '
                                            '%s, using the last one' % (name, path))

                        result[name] = _unbox_value(value)

        if result is not None:
            ctx.log.error('%s begin statement without end in %s' %
                          (cls.prefix, path))

    @staticmethod
    def aggregate_values(values: Iterable[Any], key: str) -> Any:
        aggregators = {'_max': max, '_min': min, '_sum': sum,
                       '_any': any, '_all': all}
        if key.startswith('_'):
            for aggrid, fn in aggregators.items():
                if key.startswith(aggrid):
                    return fn(values)
            raise FatalError('unknown aggregator in ' + key)
        else:
            values = list(values)
            if len(values) == 1:
                return values[0] # avoid string cast below
            else:
                return ','.join(str(v) for v in values)

    @classmethod
    def merge_results(cls, results: Iterable[ParsedResult]) -> ParsedResult:
        """
        Merge several results into one (typically for the same benchmark).

        Duplicate keys are aggregated based on their names: keys starting with
        an underscore are special. Values for keys starting with "_max",
        "_min", "_sum", "_any" or "_all" are aggregated by the corresponding
        built-in function.

        Other duplicate keys (without leading underscore) are merged by joining
        all values in a comma-separated string.

        :param results: results to merge
        :returns: a single result with aggregated values
        """
        merged = defaultdict(list)
        for res in results:
            for k, v in res.items():
                merged[k].append(v)
        return {k: cls.aggregate_values(v, k) for k, v in merged.items()}


def _box_value(value):
    return str(value)


def _unbox_value(value):
    # bool
    if value == 'True':
        return True
    if value == 'False':
        return False

    # int
    if value.isdigit():
        return int(value)

    # float
    try:
        return float(value)
    except ValueError:
        pass

    # string
    return value
